{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 使用Xception backbone做 Trnasfer Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 了解如何使用Transfer Learning\n",
    "  #### 了解Transfer Learning的優點，可以觀察模型收斂速度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 可以自行嘗試多種架構"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 14s 0us/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 15, 15, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 15, 15, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 15, 15, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 13, 13, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 13, 13, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 13, 13, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 13, 13, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 13, 13, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 13, 13, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 128)    8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 7, 7, 128)    0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 7, 7, 128)    512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 7, 7, 128)    0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 7, 7, 128)    0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 7, 7, 256)    33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 7, 7, 256)    0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 7, 7, 256)    67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 256)    32768       add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 4, 4, 256)    1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 4, 4, 256)    0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 4, 4, 256)    0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 4, 4, 728)    188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 4, 4, 728)    0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 4, 4, 728)    536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 2, 2, 728)    186368      add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 2, 2, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2, 2, 728)    2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 2, 2, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 2, 2, 728)    0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 2, 2, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 2, 2, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 2, 2, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 2, 2, 728)    0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 2, 2, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 2, 2, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 2, 2, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 2, 2, 728)    0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 2, 2, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 2, 2, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 2, 2, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 2, 2, 728)    0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 2, 2, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 2, 2, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 2, 2, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 2, 2, 728)    0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 2, 2, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 2, 2, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 2, 2, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 2, 2, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 2, 2, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 2, 2, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 2, 2, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 2, 2, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 2, 2, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 2, 2, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 2, 2, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 2, 2, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 2, 2, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 2, 2, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 2, 2, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 1, 1, 1024)   745472      add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 1, 1, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1, 1, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 1, 1, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 1, 1, 1536)   1582080     add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 1, 1, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 1, 1, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 1, 1, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 1, 1, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 1, 1, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
>>>>>>> c986c745e9834d712c22158555f55a08769431db
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.layers import Input\n",
    " \n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "#include top 決定要不要加入 fully Connected Layer\n",
    "\n",
    "'''Xception 架構'''\n",
<<<<<<< HEAD
    "\n",
    "'''Resnet 50 架構'''\n",
    "#model=keras.applications.ResNet50(include_top=False, weights='imagenet',\n",
    "                                    #input_tensor=input_tensor,\n",
    "                                    #pooling=None, classes=10)\n",
=======
    "model = keras.applications.Xception(include_top=False, weights='imagenet',\n",
    "                                    input_tensor=input_tensor,\n",
    "                                    pooling=None, classes=10)\n",
    "\n",
    "'''Resnet 50 架構'''\n",
    "# model=keras.applications.ResNet50(include_top=False, weights='imagenet',\n",
    "#                                     input_tensor=input_tensor,\n",
    "#                                     pooling=None, classes=10)\n",
>>>>>>> c986c745e9834d712c22158555f55a08769431db
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加層數"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 17,
>>>>>>> c986c745e9834d712c22158555f55a08769431db
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Model深度： 179\n"
=======
      "Model深度： 134\n"
>>>>>>> c986c745e9834d712c22158555f55a08769431db
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "/Users/chening/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/chening/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/chening/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n",
=======
      "C:\\Users\\Jude\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n",
>>>>>>> c986c745e9834d712c22158555f55a08769431db
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "x = model.output\n",
    "\n",
    "'''可以參考Cifar10實作章節'''\n",
<<<<<<< HEAD
    "\n",
=======
    "x = Flatten()(x)\n",
>>>>>>> c986c745e9834d712c22158555f55a08769431db
    "predictions = Dense(output_dim=10,activation='softmax')(x)\n",
    "model = Model(inputs=model.input, outputs=predictions)\n",
    "print('Model深度：', len(model.layers))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 鎖定特定幾層不要更新權重"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 18,
>>>>>>> c986c745e9834d712c22158555f55a08769431db
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[100:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備 Cifar 10 資料"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 19,
>>>>>>> c986c745e9834d712c22158555f55a08769431db
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "/Users/chening/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
=======
      "C:\\Users\\Jude\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
>>>>>>> c986c745e9834d712c22158555f55a08769431db
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test = normalize(x_train, x_test) \n",
    "\n",
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "WARNING:tensorflow:From /Users/chening/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      " 2304/50000 [>.............................] - ETA: 25:56 - loss: 2.3426 - acc: 0.3194"
=======
      "WARNING:tensorflow:From C:\\Users\\Jude\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 1.6010 - acc: 0.5865 - val_loss: 4.4565 - val_acc: 0.1003\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.3407 - acc: 0.6586 - val_loss: 13.1060 - val_acc: 0.0985\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.2746 - acc: 0.6612 - val_loss: 9.2282 - val_acc: 0.1023\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.1192 - acc: 0.7162 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.0959 - acc: 0.7248 - val_loss: 6.1908 - val_acc: 0.0561\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.7149 - acc: 0.7562 - val_loss: 6.7797 - val_acc: 0.1015\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.6183 - acc: 0.7918 - val_loss: 5.2490 - val_acc: 0.1258\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.5490 - acc: 0.8170 - val_loss: 9.2155 - val_acc: 0.1000\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.4844 - acc: 0.8411 - val_loss: 7.6342 - val_acc: 0.1418\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.4523 - acc: 0.8541 - val_loss: 4.5521 - val_acc: 0.1105\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.4425 - acc: 0.8602 - val_loss: 5.9193 - val_acc: 0.1137\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.3938 - acc: 0.8830 - val_loss: 5.4406 - val_acc: 0.0999\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.3595 - acc: 0.8910 - val_loss: 6.7149 - val_acc: 0.1013\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.3428 - acc: 0.8990 - val_loss: 8.7661 - val_acc: 0.1076\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.4195 - acc: 0.8918 - val_loss: 10.2107 - val_acc: 0.1082\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.3028 - acc: 0.9140 - val_loss: 7.8969 - val_acc: 0.1262\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2627 - acc: 0.9265 - val_loss: 6.0075 - val_acc: 0.1276\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2808 - acc: 0.9201 - val_loss: 4.8312 - val_acc: 0.1288\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.3434 - acc: 0.9097 - val_loss: 9.5891 - val_acc: 0.0985\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2882 - acc: 0.9236 - val_loss: 7.9042 - val_acc: 0.1035\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2588 - acc: 0.9312 - val_loss: 4.2390 - val_acc: 0.0964\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2425 - acc: 0.9336 - val_loss: 7.5907 - val_acc: 0.1048\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2158 - acc: 0.9383 - val_loss: 6.4278 - val_acc: 0.0916\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1827 - acc: 0.9474 - val_loss: 5.4299 - val_acc: 0.1229\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1995 - acc: 0.9429 - val_loss: 5.0690 - val_acc: 0.1214\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2324 - acc: 0.9405 - val_loss: 8.9013 - val_acc: 0.1270\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.3241 - acc: 0.9283 - val_loss: 7.2690 - val_acc: 0.1201\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2186 - acc: 0.9442 - val_loss: 8.0907 - val_acc: 0.1253\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1867 - acc: 0.9513 - val_loss: 6.7732 - val_acc: 0.1476\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2081 - acc: 0.9494 - val_loss: 8.6222 - val_acc: 0.1043\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2046 - acc: 0.9500 - val_loss: 9.1529 - val_acc: 0.0799\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2801 - acc: 0.9378 - val_loss: 14.0809 - val_acc: 0.0922\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2291 - acc: 0.9466 - val_loss: 14.0696 - val_acc: 0.0576\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2100 - acc: 0.9500 - val_loss: 13.1519 - val_acc: 0.0896\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2370 - acc: 0.9472 - val_loss: 12.6073 - val_acc: 0.1141\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2154 - acc: 0.9507 - val_loss: 11.5536 - val_acc: 0.1142\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2261 - acc: 0.9516 - val_loss: 11.6386 - val_acc: 0.0846\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2432 - acc: 0.9481 - val_loss: 10.6892 - val_acc: 0.1045\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1926 - acc: 0.9555 - val_loss: 9.4351 - val_acc: 0.1162\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2028 - acc: 0.9569 - val_loss: 11.3067 - val_acc: 0.1139\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1938 - acc: 0.9577 - val_loss: 8.2515 - val_acc: 0.1168\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1792 - acc: 0.9593 - val_loss: 8.2981 - val_acc: 0.1553\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1841 - acc: 0.9579 - val_loss: 7.8738 - val_acc: 0.1293\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1793 - acc: 0.9604 - val_loss: 9.9542 - val_acc: 0.1202\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1725 - acc: 0.9607 - val_loss: 9.0366 - val_acc: 0.1116\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1702 - acc: 0.9614 - val_loss: 10.3833 - val_acc: 0.1119\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1370 - acc: 0.9679 - val_loss: 9.4517 - val_acc: 0.1079\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1323 - acc: 0.9672 - val_loss: 10.2823 - val_acc: 0.1137\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1463 - acc: 0.9649 - val_loss: 7.7238 - val_acc: 0.1334\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1608 - acc: 0.9628 - val_loss: 8.7156 - val_acc: 0.1418\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1585 - acc: 0.9649 - val_loss: 9.1711 - val_acc: 0.1199\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2010 - acc: 0.9597 - val_loss: 8.2442 - val_acc: 0.1243\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.2232 - acc: 0.9564 - val_loss: 7.4937 - val_acc: 0.1435\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1637 - acc: 0.9613 - val_loss: 7.2731 - val_acc: 0.1103\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1333 - acc: 0.9682 - val_loss: 5.8438 - val_acc: 0.1546\n",
      "Epoch 56/100\n",
      "48928/50000 [============================>.] - ETA: 1s - loss: 0.1498 - acc: 0.9658"
>>>>>>> c986c745e9834d712c22158555f55a08769431db
     ]
    }
   ],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
<<<<<<< HEAD
    "model.fit(x_train,y_train,batch_size=32,epochs=100)"
=======
    "model.fit(x=x_train, y=y_train,batch_size=32,epochs=100, validation_data=(x_test, y_test))"
>>>>>>> c986c745e9834d712c22158555f55a08769431db
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
   "source": []
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 44s 871us/step - loss: 1.3698 - acc: 0.5187 - val_loss: 1.9617 - val_acc: 0.4313\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 36s 720us/step - loss: 0.9758 - acc: 0.6617 - val_loss: 2.1106 - val_acc: 0.4299\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 36s 721us/step - loss: 0.8582 - acc: 0.7024 - val_loss: 2.5708 - val_acc: 0.4225\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 36s 721us/step - loss: 0.7760 - acc: 0.7293 - val_loss: 2.3227 - val_acc: 0.4593\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.6987 - acc: 0.7568 - val_loss: 2.3145 - val_acc: 0.4627\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.6253 - acc: 0.7804 - val_loss: 2.7417 - val_acc: 0.4377\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.5494 - acc: 0.8107 - val_loss: 2.5532 - val_acc: 0.4828\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.4909 - acc: 0.8289 - val_loss: 2.5065 - val_acc: 0.4862\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.4354 - acc: 0.8484 - val_loss: 2.9680 - val_acc: 0.4440\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 36s 723us/step - loss: 0.3859 - acc: 0.8643 - val_loss: 3.6742 - val_acc: 0.4033\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.3570 - acc: 0.8755 - val_loss: 3.4556 - val_acc: 0.4471\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.2059 - acc: 0.9287 - val_loss: 4.0217 - val_acc: 0.4401\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 36s 723us/step - loss: 0.1959 - acc: 0.9320 - val_loss: 4.0019 - val_acc: 0.4450\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.1886 - acc: 0.9349 - val_loss: 4.0200 - val_acc: 0.4522\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.1813 - acc: 0.9367 - val_loss: 4.3797 - val_acc: 0.4443\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.1778 - acc: 0.9387 - val_loss: 4.8227 - val_acc: 0.4310\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 36s 721us/step - loss: 0.1726 - acc: 0.9413 - val_loss: 3.8078 - val_acc: 0.4835\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 36s 723us/step - loss: 0.1607 - acc: 0.9441 - val_loss: 4.4397 - val_acc: 0.4320\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.1573 - acc: 0.9463 - val_loss: 4.7284 - val_acc: 0.4340\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 36s 725us/step - loss: 0.1173 - acc: 0.9604 - val_loss: 5.5700 - val_acc: 0.4039\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.1214 - acc: 0.9584 - val_loss: 6.0088 - val_acc: 0.4036\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.1160 - acc: 0.9604 - val_loss: 6.0031 - val_acc: 0.3973\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.1109 - acc: 0.9621 - val_loss: 5.5717 - val_acc: 0.4215\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 36s 723us/step - loss: 0.1134 - acc: 0.9608 - val_loss: 5.2388 - val_acc: 0.4218\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.1080 - acc: 0.9637 - val_loss: 4.6178 - val_acc: 0.4607\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 36s 723us/step - loss: 0.1082 - acc: 0.9635 - val_loss: 4.1412 - val_acc: 0.4822\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.1053 - acc: 0.9638 - val_loss: 4.7016 - val_acc: 0.4626\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 36s 723us/step - loss: 0.1009 - acc: 0.9655 - val_loss: 4.0957 - val_acc: 0.4899\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 36s 727us/step - loss: 0.0795 - acc: 0.9729 - val_loss: 5.1888 - val_acc: 0.4392\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.0793 - acc: 0.9722 - val_loss: 4.3276 - val_acc: 0.4808\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 36s 723us/step - loss: 0.0725 - acc: 0.9764 - val_loss: 4.7765 - val_acc: 0.4683\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 36s 723us/step - loss: 0.0765 - acc: 0.9745 - val_loss: 4.4795 - val_acc: 0.4714\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 36s 723us/step - loss: 0.0756 - acc: 0.9747 - val_loss: 4.6243 - val_acc: 0.4509\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 36s 723us/step - loss: 0.0747 - acc: 0.9751 - val_loss: 4.9021 - val_acc: 0.4434\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 0.0744 - acc: 0.9754 - val_loss: 4.8585 - val_acc: 0.4602\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 36s 723us/step - loss: 0.0748 - acc: 0.9748 - val_loss: 4.6013 - val_acc: 0.4632\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 36s 723us/step - loss: 0.0668 - acc: 0.9773 - val_loss: 5.3400 - val_acc: 0.4378\n",
      "Epoch 68/100\n",
      " 3968/50000 [=>............................] - ETA: 30s - loss: 0.0620 - acc: 0.9786Epoch 90/100\n",
      "50000/50000 [==============================] - 37s 730us/step - loss: 0.0568 - acc: 0.9817 - val_loss: 5.6019 - val_acc: 0.4332\n",
      "Epoch 91/100\n",
      "37568/50000 [=====================>........] - ETA: 8s - loss: 0.0588 - acc: 0.980"
     ]
    }
   ],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(x=x_train, y=y_train,batch_size=32,epochs=100, validation_data=(x_test, y_test))"
   ]
>>>>>>> c986c745e9834d712c22158555f55a08769431db
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
=======
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
>>>>>>> c986c745e9834d712c22158555f55a08769431db
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.6.7"
=======
   "version": "3.7.3"
>>>>>>> c986c745e9834d712c22158555f55a08769431db
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
